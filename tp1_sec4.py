#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TP1 Section 4: Mappage Tonal et Encodage d'Affichage

Ce script:
1. Charge les images XYZ depuis ./images_intermediaires_sec3/*_camera_xyz.tiff
2. Applique l'ajustement de luminosit√© (√Ä IMPL√âMENTER)
3. Applique le mappage tonal:
   - Lin√©aire (impl√©ment√©)
   - Reinhard (√Ä IMPL√âMENTER)
4. Convertit XYZ vers sRGB lin√©aire (impl√©ment√©)
5. Applique l'OETF sRGB (impl√©ment√©)
6. Sauvegarde le JPEG final (impl√©ment√©)
7. Analyse les artefacts JPEG (√Ä IMPL√âMENTER)
8. Sauvegarde dans ./images_intermediaires_sec4/

Usage:
    python tp1_sec4.py --input-dir images_intermediaires_sec3 --output-dir images_intermediaires_sec4
"""

import numpy as np
import glob
import os
from PIL import Image

from tp1_io import (
    load_tiff,
    save_tiff16,
    linear_to_srgb,
    xyz_to_linear_srgb,
    quantize_to_8bit,
)
from tp1_rapport import (
    html_document,
    section,
    subsection,
    figure,
    table,
    algorithm_box,
    formula_box,
    save_report,
    comparison_grid,
    create_tonemapping_curves_figure,
    create_tonemapping_comparison_figure,
    create_oetf_comparison_figure,
    create_dynamic_range_figure,
)


# =============================================================================
# Ajustement de Luminosit√©
# =============================================================================


def adjust_brightness(xyz_image, percentile=99):
    """
    Ajuster la luminosit√© de l'image en normalisant au percentile donn√©.

    Mesure le percentile sp√©cifi√© du canal Y (luminance) et divise
    toute l'image par cette valeur pour normaliser la luminosit√©.

    Args:
        xyz_image: Image XYZ [H, W, 3]
        percentile: Percentile √† utiliser pour la normalisation (d√©faut: 99)

    Returns:
        Image XYZ avec luminosit√© ajust√©e

    Indices:
    1. Extraire le canal Y (luminance): Y = xyz_image[:, :, 1]
    2. Filtrer les valeurs valides (Y > 0)
    3. Calculer le percentile sp√©cifi√© des valeurs valides
    4. Diviser toute l'image par cette valeur
    5. Retourner l'image ajust√©e
    """
    Y = xyz_image[:, :, 1]
    
    # Compute the percentile of luminance (excluding zeros/negatives)
    valid_Y = Y[Y > 0]
    if len(valid_Y) == 0:
        print("    Warning: No valid luminance values, skipping brightness adjustment")
        return xyz_image.copy()
    
    percentile_value = np.percentile(valid_Y, percentile)
    
    if percentile_value <= 0:
        print("    Warning: Percentile value <= 0, skipping brightness adjustment")
        return xyz_image.copy()
    
    # Divide the entire image by the percentile value
    adjusted = xyz_image / percentile_value
    
    print(f"    Brightness adjustment: divided by {percentile_value:.6f} (1st percentile)")
    
    return adjusted

    # raise NotImplementedError("Ajustement de luminosit√© √† impl√©menter")

    # L'ajustement de luminosit√© est d√©j√† impl√©ment√©?

# =============================================================================
# Op√©rateurs de Mappage Tonal
# =============================================================================


def tonemap_linear(xyz_image):
    """
    Mappage tonal lin√©aire (identit√©) - pas de compression.

    Les valeurs > 1 seront clipp√©es lors de la conversion finale.

    Args:
        xyz_image: Image XYZ [H, W, 3]

    Returns:
        Image XYZ (copie)
    """
    return xyz_image.copy()


def tonemap_reinhard(xyz_image):
    """
    Mappage tonal de Reinhard: L_out = L_in / (1 + L_in)

    Appliqu√© √† Y (luminance), X et Z sont mis √† l'√©chelle proportionnellement.

    R√©f√©rence: "Photographic Tone Reproduction for Digital Images" (2002)

    Args:
        xyz_image: Image XYZ [H, W, 3]

    Returns:
        Image XYZ avec mappage tonal appliqu√©

    Indices:
    1. Extraire le canal Y (luminance): Y = xyz_image[:, :, 1]
    2. Appliquer la formule: Y_mapped = Y / (1 + Y)
    3. Calculer le ratio: scale = Y_mapped / Y (attention aux divisions par z√©ro!)
    4. Appliquer ce ratio √† X et Z √©galement
    5. Retourner l'image r√©sultante
    """
    Y = xyz_image[:, :, 1]
    Y_mapped = Y / (1.0 + Y)
    scale = np.divide(Y_mapped, Y, out=np.ones_like(Y), where=Y > 1e-9)

    return xyz_image * scale[:, :, np.newaxis]

# =============================================================================
# Sauvegarde d'Images
# =============================================================================


def save_jpeg(img_8bit, filepath, quality=95):
    """
    Sauvegarder une image en JPEG.

    Args:
        img_8bit: Image uint8 [H, W, 3]
        filepath: Chemin de sortie
        quality: Qualit√© JPEG (1-100, d√©faut: 95)
    """
    Image.fromarray(img_8bit, mode="RGB").save(filepath, "JPEG", quality=quality)
    print(f"  Saved JPEG: {filepath}")


def save_png(img_8bit, filepath):
    """
    Sauvegarder une image en PNG (sans perte).

    Args:
        img_8bit: Image uint8 [H, W, 3]
        filepath: Chemin de sortie
    """
    Image.fromarray(img_8bit, mode="RGB").save(filepath, "PNG")
    print(f"  Saved PNG: {filepath}")


# =============================================================================
# Analyse de Plage Dynamique
# =============================================================================


def analyze_dynamic_range(image_linear):
    """Analyser l'√©cr√™tage des hautes lumi√®res et l'√©crasement des ombres."""
    lum = (
        0.2126 * image_linear[:, :, 0]
        + 0.7152 * image_linear[:, :, 1]
        + 0.0722 * image_linear[:, :, 2]
    )

    highlight_pct = np.sum(lum >= 0.99) / lum.size * 100
    shadow_pct = np.sum(lum <= 0.01) / lum.size * 100

    valid = lum[lum > 0]
    if len(valid) > 0:
        min_lum, max_lum = np.percentile(valid, 1), np.percentile(valid, 99)
        dr_stops = np.log2(max_lum / min_lum) if min_lum > 0 else 0
    else:
        dr_stops = 0

    return {
        "highlight_clipped_percent": highlight_pct,
        "shadow_crushed_percent": shadow_pct,
        "dynamic_range_stops": dr_stops,
        "min_luminance": float(np.min(lum)),
        "max_luminance": float(np.max(lum)),
        "mean_luminance": float(np.mean(lum)),
    }


# =============================================================================
# G√©n√©ration du Rapport HTML
# =============================================================================


def generate_report(results, output_dir):
    """
    G√©n√©rer un rapport HTML template pour toutes les sections du TP1.
    
    Cr√©e un rapport complet avec:
    - Section 1: Chargement et compr√©hension des donn√©es RAW
    - Section 2: D√©matri√ßage (Demosaicking)
    - Section 3: Balance des Blancs (White Balance)
    - Section 4: Mappage tonal et encodage d'affichage
    
    Inclut toutes les figures g√©n√©r√©es et des espaces "√Ä remplir" pour l'√©tudiant.
    """
    # D√©finir les r√©pertoires de sortie pour chaque section
    # Si output_dir est "images_intermediaires_sec4", base_dir sera le r√©pertoire parent
    if "images_intermediaires_sec" in os.path.basename(output_dir):
        base_dir = os.path.dirname(output_dir) or "."
    else:
        base_dir = output_dir
    
    sec1_dir = os.path.join(base_dir, "images_intermediaires_sec1")
    sec2_dir = os.path.join(base_dir, "images_intermediaires_sec2")
    sec3_dir = os.path.join(base_dir, "images_intermediaires_sec3")
    sec4_dir = output_dir
    
    # Obtenir la liste des basenames (noms de fichiers sans extension)
    basenames = [result["basename"] for result in results] if results else []
    
    # Si aucun r√©sultat, chercher les fichiers dans les r√©pertoires
    if not basenames:
        # Chercher dans sec1
        tiff_files = glob.glob(os.path.join(sec1_dir, "*.tiff"))
        basenames = [os.path.splitext(os.path.basename(f))[0] for f in tiff_files if "zoom" not in f]
        basenames = list(set(basenames))  # D√©dupliquer
    
    # Limiter √† 2 images d'exemple pour rendre le rapport plus court
    basenames = sorted(basenames)[:3]
    content = ""
    
    # =============================================================================
    # SECTION 1: Chargement et Compr√©hension des Donn√©es RAW
    # =============================================================================
    sec1_content = ""
    
    # Texte d'introduction pour la section 1
    sec1_content += subsection(
        "Introduction",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #4fc3f7;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        '''Le format RAW contient les donn√©es brutes du capteur sans traitement. 
        Ces donn√©es sont enregistr√©es en motif de Bayer, o√π chaque pixel ne capture qu'une seule couleur (R, G ou B). 
        J'ai observ√© que les images brutes apparaissent tr√®s sombres car elles sont lin√©aires, le capteur compte les photons proportionnellement, et n'ont pas encore subi de correction. 
        La normalisation est essentielle pour ramener les valeurs (dans mon cas sur 12, 14 et 16 bits) vers un intervalle [0, 1]. 
        On soustrait aussi un petit niveau de noir du capteur pour contrer le bruit.'''
        '</p></div>'
    )
    
    for basename in basenames:
        sec1_img_content = ""
        
        # Figure: Zoom sur la mosa√Øque Bayer
        zoom_path = os.path.join(sec1_dir, f"{basename}_zoom16x16.png")
        if os.path.exists(zoom_path):
            sec1_img_content += subsection(
                f"R√©gion 16√ó16 de la mosa√Øque - {basename}",
                figure(f"../images_intermediaires_sec1/{basename}_zoom16x16.png",
                       "Zoom sur une r√©gion 16√ó16 montrant les valeurs normalis√©es et le motif de Bayer color√©.")
            )
        
        if sec1_img_content:
            sec1_content += section(f"Image: {basename}", sec1_img_content)
    
    # Analyse et observations
    sec1_content += subsection(
        "Analyse et observations",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #4fc3f7;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        """
                J'ai remarqu√© que mes images personnelles ont 14 bits de profondeur.
                Celles fourni varie entre 12, 14 et m√™me 16 bits pour le pelican. 
                On comprend vite l'importance de la normalisation pour ramener
                toutes ces valeurs dans un seul intervalle pour le traitement.
            
                Aussi, en zoomant sur le 16x16, on peut voir le filtre de Bayer de l'image.
                Les filtre change d'image en image.
                L'image n'est pas encore d√©matric√©e donc le filtre est tr√®s apparent quand on zoom.
        
                Finalement, le niveau de noir n'est jamais √† 0 dans les m√©tadonn√©es.
                J'assume que c'est le capteur qui capture de la lumi√®re parasite.
                Le code soustrait on offset avant la normalisation pour √ßa.
        """
        '</p></div>'
    )
    
    content += section("Section 1: Chargement et Compr√©hension des Donn√©es RAW", sec1_content, icon="üì∑")
    
    # =============================================================================
    # SECTION 2: D√©matri√ßage (Demosaicking)
    # =============================================================================
    sec2_content = ""
    
    # Texte d'introduction pour la section 2
    sec2_content += subsection(
        "Introduction",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #778da9;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        "Le d√©matri√ßage consiste √† interpoler les couleurs manquantes pour obtenir "
        "une image RGB compl√®te. La m√©thode bilin√©aire est rapide mais elle donne des artefacts "
        "de couleur sur les contours (visible quand on zoom). "
        "La m√©thode Malvar am√©liore le r√©sultat en utilisant la luminance pour "
        "corriger l'interpolation des canaux rouge et bleu. "
        "Visuellement, on voit donc des contours plus nets et moins d'artefacts de fausses couleurs."
        '</p>'
        '</div>'
    )
    
    for basename in basenames:
        sec2_img_content = ""
        
        # Figure: Comparaison des m√©thodes
        comp_path = os.path.join(sec2_dir, f"{basename}_comparison.png")
        if os.path.exists(comp_path):
            sec2_img_content += subsection(
                f"Comparaison des m√©thodes - {basename}",
                figure(f"../images_intermediaires_sec2/{basename}_comparison.png",
                       "Comparaison des m√©thodes de d√©matri√ßage")
            )
        
        # Figure: Zoom sur les artefacts
        zoom_path = os.path.join(sec2_dir, f"{basename}_zoom.png")
        if os.path.exists(zoom_path):
            sec2_img_content += subsection(
                f"Zoom sur les artefacts - {basename}",
                figure(f"../images_intermediaires_sec2/{basename}_zoom.png",
                       "Recadrages montrant les artefacts de contour")
            )
        
        if sec2_img_content:
            sec2_content += section(f"Image: {basename}", sec2_img_content)
    
    # Analyse et observations
    sec2_content += subsection(
        "Analyse et observations",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #778da9;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        """
            Th√©oriquement, l'interpolation bilin√©aire devrait pr√©senter des artefacts visibles 
            sur les contours nets. Cela est d√ª au fait qu'elle traite chaque canal ind√©pendamment 
            sans tenir compte de ce que les couleurs autours ont comme luminosit√©.
            La m√©thode Malvar-Cutler devrait corriger cela en utilisant le gradient du canal vert 
            pour faire l'interpolation du rouge et du bleu. Les deux algorithmes sont lin√©aire et donc peu couteux,
            mais Malvar prend un temps un peu plus long. Cela est probablement d√ª au fait que la convolution se fait sur
            des matrices plus larges. Cependant, quand je r√©vise mes r√©sultats
            obtenus avec les algorithmes, la diff√©rence des artefacts semble n√©gligeable, m√™me en zoomant aux extr√©mit√©s.
            Tout de m√™me, les photos ont l'allure attendue par le rematri√ßage.
        """
        '</p>'
        '</div>'
    )
    
    content += section("Section 2: D√©matri√ßage (Demosaicking)", sec2_content, icon="üé®")
    
    # =============================================================================
    # SECTION 3: Balance des Blancs (White Balance)
    # =============================================================================
    sec3_content = ""
    
    # Texte d'introduction pour la section 3
    sec3_content += subsection(
        "Introduction",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #e94560;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        "La balance des blancs sert √† corriger la teinte globale de l'image pour "
        "que les objets neutres soit gris. L'algorithme Grey World dit que la moyenne de l'image "
        "est grise, ce qui est mauvais pour les images avec une couleur dominante (comme ma photo de for√™t verte). "
        "La m√©thode de la r√©gion neutre automatique est meilleure si une zone blanche est pr√©sente. "
        '</p>'
        '</div>'
    )
    
    for basename in basenames:
        sec3_img_content = ""
        
        # Figure: Comparaison des m√©thodes
        comp_path = os.path.join(sec3_dir, f"{basename}_comparison.png")
        if os.path.exists(comp_path):
            sec3_img_content += subsection(
                f"Comparaison des m√©thodes - {basename}",
                figure(f"../images_intermediaires_sec3/{basename}_comparison.png",
                       "Comparaison des m√©thodes de balance des blancs")
            )
        
        # Figure: Conversion XYZ
        xyz_path = os.path.join(sec3_dir, f"{basename}_xyz_comparison.png")
        if os.path.exists(xyz_path):
            sec3_img_content += subsection(
                f"Conversion XYZ - {basename}",
                figure(f"../images_intermediaires_sec3/{basename}_xyz_comparison.png",
                       "Images converties en XYZ puis reconverties en sRGB")
            )
        
        if sec3_img_content:
            sec3_content += section(f"Image: {basename}", sec3_img_content)
    
    # Analyse et observations
    sec3_content += subsection(
        "Analyse et observations",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #e94560;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
    """
        Les multiplicateurs me dise la couleur dominante de la source lumineuse. 
        Par exemple, pour ma photo Ahsoka, cela signifie que le capteur a re√ßu beaucoup de rouge et qu'il faut le diminuer pour √©quilibrer l'image. 
        Ensuite, selon mes r√©sultats, avec l'algorithme Malvar, l'algorithme de balance cam√©ra obtient les meilleurs images. C'est l'algorithme qui utilise
        les raw datas directement, donc donne un meilleur point de vue du moment qui √† √©t√© captur√©. La photo Ahsoka √† cependant des r√©gions
        trop lumineuses o√π les lumi√®res. Je crois que la balance cam√©ra √† de la mis√®re avec les √©clairage qui varie dans l'image.
        La conversion vers l'espace XYZ standardise les couleurs
        peut importe pour quel appareil, ce qui est n√©cessaire avant de convertir vers le sRGB.
    """
        '</p>'
        '</div>'
    )
    
    content += section("Section 3: Balance des Blancs (White Balance)", sec3_content, icon="‚ö™")
    
    # =============================================================================
    # SECTION 4: Mappage Tonal et Encodage d'Affichage
    # =============================================================================
    sec4_content = ""
    
    # Texte d'introduction pour la section 4
    sec4_content += subsection(
        "Introduction",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #778da9;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        "Le mappage tonal adapte la grande plage dynamique du capteur (comme HDR)"
        "√† l'affichage limit√©. "
        "L'op√©rateur lin√©aire coupe les hautes lumi√®res mais en "
        "perdant les d√©tails dans les zones claires. L'op√©rateur de Reinhard compresse ces hautes "
        "lumi√®res avec une courbe non-lin√©aire, pr√©servant les d√©tails. L'OETF sRGB applique "
        " une correction gamma pour que la luminosit√© "
        "per√ßue soit correcte. Finalament, la compression JPEG fait appara√Ætre des artefacts de blocs visibles "
        "√† cause de la perte d'information des hautes fr√©quences dans la compression."
        '</p>'
        '</div>'
    )
    
    # Concepts et algorithmes
    algorithms = algorithm_box(
        "A) Ajustement de luminosit√©",
        "<p>Division par le 99e percentile.</p>",
    )
    algorithms += algorithm_box(
        "B) Mappage tonal",
        "<p><b>Lin√©aire:</b> Pas de compression.</p>"
        "<p><b>Reinhard:</b> <code>L_out = L_in / (1 + L_in)</code>.</p>",
    )
    algorithms += algorithm_box(
        "C) Conversion XYZ ‚Üí sRGB",
        "<p>Matrice standard D65 suivie de l'OETF sRGB.</p>",
    )
    algorithms += algorithm_box(
        "D) OETF sRGB",
        formula_box("sRGB = 1.055 √ó lin√©aire^(1/2.4) ‚àí 0.055")

    )
    algorithms += algorithm_box(
        "E) Analyse des artefacts JPEG",
        "<p>Sauvegarde en diff√©rentes qualit√©s et analyse des artefacts.</p>",
    )
    
    sec4_content += subsection("Concepts et algorithmes", algorithms)
    
    # Figure: Courbes de mappage tonal
    curves_path = os.path.join(sec4_dir, "tonemapping_curves.png")
    if os.path.exists(curves_path):
        sec4_content += subsection(
            "Courbes de mappage tonal",
            figure("tonemapping_curves.png", "Comparaison des courbes de r√©ponse")
        )
    
    # Figures pour chaque image
    # Utiliser results si disponible, sinon utiliser basenames
    # Filtrer pour ne garder que les 2 images s√©lectionn√©es
    if results:
        images_to_process = [r for r in results if r["basename"] in basenames]
    else:
        images_to_process = [{"basename": bn} for bn in basenames]
    
    for result in images_to_process:
        basename = result["basename"]
        dr = result.get("dynamic_range", {})
        
        sec4_img_content = ""
        
        # Figure: Comparaison des op√©rateurs
        comp_path = os.path.join(sec4_dir, f"{basename}_tonemapping_comparison.png")
        if os.path.exists(comp_path):
            sec4_img_content += subsection(
                "Comparaison des op√©rateurs",
                figure(
                    f"{basename}_tonemapping_comparison.png",
                    "Comparaison: Lin√©aire, Reinhard",
                ),
            )
        
        # Figure: Avant/Apr√®s OETF
        oetf_path = os.path.join(sec4_dir, f"{basename}_oetf_comparison.png")
        if os.path.exists(oetf_path):
            sec4_img_content += subsection(
                "Avant/Apr√®s OETF",
                figure(
                    f"{basename}_oetf_comparison.png",
                    "L'OETF encode les valeurs lin√©aires pour l'affichage",
                ),
            )
        
        # Figure: Image finale
        final_path = os.path.join(sec4_dir, f"{basename}_final.jpg")
        if os.path.exists(final_path):
            sec4_img_content += subsection(
                "Image finale",
                figure(f"{basename}_final.jpg", "Image JPEG finale (qualit√© 95)"),
            )
        
        # Figure: Plage dynamique
        dr_path = os.path.join(sec4_dir, f"{basename}_dynamic_range.png")
        if os.path.exists(dr_path):
            dr_table = ""
            if dr:
                dr_table = table(
                    ["M√©trique", "Valeur"],
                    [
                        [
                            "Plage dynamique",
                            f"{dr.get('dynamic_range_stops', 0):.1f} stops",
                        ],
                        [
                            "Hautes lumi√®res √©cr√™t√©es",
                            f"{dr.get('highlight_clipped_percent', 0):.2f}%",
                        ],
                        ["Ombres √©cras√©es", f"{dr.get('shadow_crushed_percent', 0):.2f}%"],
                    ],
                )
            sec4_img_content += subsection(
                "Plage dynamique",
                figure(
                    f"{basename}_dynamic_range.png", "Analyse des hautes lumi√®res et ombres"
                ) + dr_table,
            )
            jpeg_metrics = result.get("jpeg_metrics", [])
            if jpeg_metrics:
                rows = []
                for m in jpeg_metrics:
                    rows.append([
                        f"JPEG Q={m['quality']}",
                        f"{m['size_kb']:.1f} KB",
                        f"{m['compression_ratio']:.1f}:1",
                        f"{m['psnr']:.2f} dB"
                    ])
                jpeg_table = table(
                    ["Qualit√©", "Taille", "Ratio", "PSNR"],
                    rows
                )
                sec4_img_content += subsection(
                    "Analyse de compression JPEG",
                    jpeg_table
                )

                artifacts_path = os.path.join(sec4_dir, f"{basename}_jpeg_artifacts.png")
                if os.path.exists(artifacts_path):
                    sec4_img_content += subsection(
                        "Artefacts visuels (Zoom)",
                        figure(f"{basename}_jpeg_artifacts.png", "Comparaison visuelle: R√©f√©rence vs JPEG Q=25")
                    )
        
        if sec4_img_content:
            sec4_content += section(basename, sec4_img_content)
    
    # Analyse et observations
    sec4_content += subsection(
        "Analyse et observations", 
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #778da9;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        '''Comme discut√© dans l'introduction, le mappage lin√©aire coupe les hautes lumi√®res. On peut voir dans les photos les zones"
        "coup√©s. Les donn√©es nous dise 0.60% pour Ahsoka, ce qui est tr√®s faible donc peu de perte d'information."
        "Sans l'OETF sRGB, l'image lin√©aire est sombre et manque de lumi√®re. L'OETF restaure la perception naturelle de la luminosit√©. L'image finale affiche une plage dynamique de 6.9 stops. 
        Les ombres sont plus √©cras√©es (1.78%) que les hautes lumi√®res. 
        Cela est probablement √† cause du storage 8 bits qui ne peut pas contenir toute la plage dynamique captur√©e par le capteur (16 bits).
        Le tableau montre le compromis taille/qualit√©. 
        √Ä Q=95, la qualit√© est maximale (PSNR 30.8 dB) mais le fichier est lourd (7.6 MB). 
        √Ä Q=25, la compression est immense (63:1) et le fichier est de seulement 542 KB, mais la qualit√© visuelle n'est pas bonne (PSNR 27.35 dB et des artefacts de blocs sur les contours). 
        Je crois que Q=75 offre le meilleur compromis.'''
        '</p>'
        '</div>'
    )
    
    content += section("Section 4: Mappage Tonal et Encodage d'Affichage", sec4_content, icon="üé®")
    
    # =============================================================================
    # GRILLE DE COMPARAISON DES IMAGES FINALES
    # =============================================================================
    # Collecter toutes les images finales JPG de la section 4 et leurs r√©f√©rences
    comparisons = []
    jpg_files = sorted(glob.glob(os.path.join(sec4_dir, "*_final.jpg")))
    
    for jpg_path in jpg_files:
        basename = os.path.basename(jpg_path).replace("_final.jpg", "")
        final_src = os.path.basename(jpg_path)
        
        # Chercher l'image de r√©f√©rence correspondante
        reference_src = None
        srgb_path = os.path.join(sec1_dir, f"{basename}_srgb.jpg")
        if os.path.exists(srgb_path):
            reference_src = f"../images_intermediaires_sec1/{basename}_srgb.jpg"
        
        if reference_src:
            comparisons.append({
                "basename": basename,
                "final_src": final_src,
                "reference_src": reference_src,
                "final_alt": f"Image finale - {basename}",
                "reference_alt": f"R√©f√©rence sRGB - {basename}"
            })
        else:
            # Si pas de r√©f√©rence, ajouter quand m√™me l'image finale seule
            comparisons.append({
                "basename": basename,
                "final_src": final_src,
                "reference_src": final_src,  # Dupliquer pour l'affichage
                "final_alt": f"Image finale - {basename}",
                "reference_alt": f"Image finale - {basename}"
            })
    
    if comparisons:
        grid_content = subsection(
            "Comparaison: Vos r√©sultats vs R√©f√©rences sRGB",
            '<p style="color: #a0a0a0; margin-bottom: 20px;">Comparez vos images finales avec les aper√ßus sRGB g√©n√©r√©s par rawpy. Cliquez sur une image pour l\'agrandir.</p>'
        )
        grid_content += comparison_grid(comparisons)
        content += section("Comparaison des Images Finales", grid_content, icon="üñºÔ∏è")
    
    # =============================================================================
    # CONCLUSION G√âN√âRALE
    # =============================================================================
    conclusion_content = subsection(
        "Conclusion",
        '<div style="background: rgba(0,0,0,0.2); padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #ffd54f;">'
        '<p style="color: #a0a0a0; font-style: italic;">'
        '''
        Le pipeline a permis de refaire la formation d'une image √† partir des donn√©es raw venant d'une capteur.
        Dans mon cas, j'utilisais un Canon EOS REBEL T3i avec les r√©glage suivant : 
        - ISO-2500
        - F-stop f/2
        - Exposure time 1/160 sec
        - Bias 0 step
        - Metering mode Pattern
        En partant des donn√©es brutes du capteur, j'ai fait la normalisation, d√©matri√ßage, balance des blancs, et mappage tonal.
        J'ai constater l'importance du mappage tonal (Reinhard) pour compresser la dynamique 14 bits vers l'affichage 8 bits sans perdre les hautes lumi√®res.
        La qualit√© est beaucoup moins bonne avec les pertes d'informations.
        Finalement, en comparant, mes images sorties du pipeline sont tr√®s semblables aux r√©f√©rences, 
        quoique que les miennes semble trop clair.
        '''
        '</p>'
        '</div>'
    )
    
    content += section("Conclusion", conclusion_content, icon="üìù")
    
    # G√©n√©rer le document HTML final
    html = html_document(
        "Rapport TP1 - Maxime B√©dard",
        "",
        "üì∏",
        content,
        accent_color="#778da9",
    )
    
    save_report(html, os.path.join(output_dir, "rapport_complet.html"))


# =============================================================================
# Traitement Principal
# =============================================================================


def process_display_encoding(
    input_dir="images_intermediaires_sec3",
    output_dir="images_intermediaires_sec4",
    input_suffix="_camera_xyz.tiff",
):
    """Traiter les images XYZ avec mappage tonal et encodage d'affichage."""
    os.makedirs(output_dir, exist_ok=True)

    tiff_files = sorted(glob.glob(os.path.join(input_dir, f"*{input_suffix}")))

    if not tiff_files:
        print(f"Aucun fichier *{input_suffix} trouv√© dans {input_dir}/")
        return

    print(f"\n{'#'*60}")
    print("# Section 4: Mappage Tonal et Encodage d'Affichage")
    print(f"{'#'*60}")
    print(f"\n{len(tiff_files)} fichier(s) trouv√©(s)")

    # G√©n√©rer la figure des courbes une seule fois
    create_tonemapping_curves_figure(os.path.join(output_dir, "tonemapping_curves.png"))

    results = []

    for tiff_path in tiff_files:
        basename = os.path.basename(tiff_path).replace(input_suffix, "")

        print(f"\n{'='*60}")
        print(f"Traitement: {basename}")
        print("=" * 60)

        try:
            xyz_image = load_tiff(tiff_path)
            result = {"basename": basename}

            # Ajustement de luminosit√© (√† impl√©menter par l'√©tudiant)
            print("  [0] Ajustement de luminosit√©...")
            xyz_image = adjust_brightness(xyz_image, percentile=99)

            # Comparaison des op√©rateurs de mappage tonal
            print("  [A] Comparaison du mappage tonal...")
            tonemap_funcs = {
                "Lin√©aire": tonemap_linear,
                "Reinhard": tonemap_reinhard,
            }
            srgb_results = create_tonemapping_comparison_figure(
                xyz_image,
                os.path.join(output_dir, f"{basename}_tonemapping_comparison.png"),
                tonemap_funcs,
                xyz_to_linear_srgb,
                linear_to_srgb,
                title=f"Mappage tonal - {basename}",
            )

            # Utiliser lin√©aire pour la suite (ou Reinhard si impl√©ment√©)
            xyz_tonemapped = tonemap_linear(xyz_image)
            rgb_linear = xyz_to_linear_srgb(xyz_tonemapped)
            rgb_linear = np.clip(rgb_linear, 0, 1)
            srgb = linear_to_srgb(rgb_linear)

            # Sauvegarder les r√©sultats
            for name, img in srgb_results.items():
                save_tiff16(
                    img, os.path.join(output_dir, f"{basename}_{name.lower()}.tiff")
                )

            # Comparaison OETF
            print("  [B] Comparaison OETF...")
            create_oetf_comparison_figure(
                rgb_linear,
                srgb,
                os.path.join(output_dir, f"{basename}_oetf_comparison.png"),
                title=f"OETF sRGB - {basename}",
            )

            # Sauvegarder l'image finale en JPEG
            print("  [C] Sauvegarde de l'image finale...")
            img_8bit = quantize_to_8bit(srgb)

            final_jpg = os.path.join(output_dir, f"{basename}_final.jpg")
            save_jpeg(img_8bit, final_jpg, quality=95)

            # - Sauvegarder en diff√©rentes qualit√©s (95, 75, 50, 25)
            # - Comparer avec PNG (sans perte)
            # - Visualiser les artefacts de compression
            # - Cr√©er un graphique taille vs qualit√©
            print("  [!] Analyse des artefacts JPEG...")
            ref_png = os.path.join(output_dir, f"{basename}_ref.png") # png
            save_png(img_8bit, ref_png)

            ref_taille_kb = os.path.getsize(ref_png) / 1024.0 # la taille de l'image
            img_ref_float = img_8bit.astype(np.float32) / 255.0 #float

            jpeg_data = []
            qualites = [95, 75, 50, 25]
            for q in qualites:
                jpg_path = os.path.join(output_dir, f"{basename}_q{q}.jpg") # sauvegarde
                save_jpeg(img_8bit, jpg_path, quality=q)
                taille_kb = os.path.getsize(jpg_path) / 1024.0
                ratio = ref_taille_kb / taille_kb if taille_kb > 0 else 0

                img_jpg_loaded = np.array(Image.open(jpg_path)).astype(np.float32) / 255.0
                mse = np.mean((img_ref_float - img_jpg_loaded) ** 2)
                if mse == 0:
                    psnr = float('inf')
                else:
                    psnr = 10 * np.log10(1.0 / mse)
                jpeg_data.append({
                    "quality": q,
                    "size_kb": taille_kb,
                    "psnr": psnr,
                    "compression_ratio": ratio
                })
            result["jpeg_metrics"] = jpeg_data

            # Analyse de plage dynamique
            print("  [D] Analyse de plage dynamique...")
            dr_analysis = analyze_dynamic_range(rgb_linear)
            result["dynamic_range"] = dr_analysis
            print(
                f"    Plage dynamique: {dr_analysis['dynamic_range_stops']:.1f} stops"
            )

            create_dynamic_range_figure(
                rgb_linear,
                srgb,
                dr_analysis,
                os.path.join(output_dir, f"{basename}_dynamic_range.png"),
                title=f"Plage dynamique - {basename}",
            )

            results.append(result)

        except Exception as e:
            print(f"\nErreur lors du traitement de {tiff_path}: {e}")
            import traceback

            traceback.print_exc()

    if results:
        generate_report(results, output_dir)

    print(f"\n{'='*60}")
    print(f"Termin√©! {len(results)} image(s) trait√©e(s) ‚Üí {output_dir}/")
    print("=" * 60)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="TP1 Section 4: Mappage Tonal et Encodage"
    )
    parser.add_argument("--input-dir", "-i", default="images_intermediaires_sec3")
    parser.add_argument("--output-dir", "-o", default="images_intermediaires_sec4")
    parser.add_argument("--suffix", "-s", default="_camera_xyz.tiff")

    args = parser.parse_args()
    process_display_encoding(args.input_dir, args.output_dir, args.suffix)
